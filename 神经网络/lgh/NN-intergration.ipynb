{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train: 2034\n",
      "num test : 1353\n",
      "X_train shape: (2034, 20)\n",
      "Y_train shape: (2034,)\n",
      "X_test shape: (1353, 20)\n",
      "Y_test shape: (1353,)\n",
      "model 1\n",
      "Accuracy 0.401330 = 543 / 1353\n",
      "model 2\n",
      "Accuracy 0.341463 = 462 / 1353\n",
      "model 3\n",
      "Accuracy 0.333333 = 451 / 1353\n",
      "model 4\n",
      "Accuracy 0.430894 = 583 / 1353\n",
      "model 5\n",
      "Accuracy 0.464893 = 629 / 1353\n",
      "num layer: 3\n",
      "num iterations: 7000\n",
      "active func: tanh\n",
      "num node: [4, 8, 16, 32, 64]\n",
      "learn rate: 1e-06\n",
      "update method: exp\n",
      "reg para: 0.2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAACgCAYAAAD9/EDKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAG3pJREFUeJzt3XuUHWWZ7/HvL01ChySAQzAjNBJgAg4wcmmk8Rx1iEHhCBIYWCPjGC5zAFGj5kTOeF3IQR316Im9ZlAzY+Qml8CAOpEBI0KSAYWGhIsaEU24mEZAbiEJdoAkz/mj3p1Udnb3ru6kdu/u/n3W2qvr8lbVU7V717PrfWvXq4jAzMysL6MGOwAzM2t+ThZmZlaXk4WZmdXlZGFmZnU5WZiZWV1OFmZmVpeTxQgl6WJJVw92HMOJpA9JekbSOkl7FCj/uKTj0vBnJM3LzTtV0qq0riMkHSTpQUlrJX2szP1oNpLOlnRXwbJXSPpi2TGNRDsNdgBWDknrcqO7AK8AG9P4Bxsf0fAmaTQwBzgmIh7q7/IR8U9Vk74OzIyI/0jr/y6wKCIO3+5g+0nSscDVEdHW6G1b8/CVxTAVEeMrL+D3wHtz064Z7Ph2JEnN8KVnEtAKLN9B69u3al3V44U1yfGxIc7JYmQbI+mqVLWxXNJRlRmS9pJ0k6RnJT3WV9WHpBMlPSBpTao6ubhq/tsk/VzS6jT/7DR9rKT/J+kJSS9JuitNO1ZSd9U68lU2F0u6UdLVktYAZ0s6WtLdaRtPSbpU0pjc8odIuk3SC6mq6DOS/lzSn/JVRpKOTPs8usZ+7iypU9If0qszTTsQeCQVWy3pjl6O04y0r89L+mzVvIvT/uycrgpbgIckrUzrmwpcmqqlDkzlvi7p92l/5koam9Z1rKRuSZ+U9DRweZp+UqrKWp3ejzdXHd8LJf0ivRfXS2qVNA64FdgrbXudpL1q7NsVkr4l6dZU5mfp+HZKelHSbyQdkSv/l5IWp1iWSzo5N28PSQvS/9O9wAFV23pT7r18RNLf9nK8J0q6OW3jBUl3SvI5b6Aiwq9h/gIeB46rmnYxsB54D9mJ6cvAPWneKGAZcBEwBtgfeBQ4vpf1Hwv8VVruzcAzwClp3r7AWuDvgNHAHsDhad43gcXA3imG/wbsnNbX3ds+pNhfA05J2xwLtAPHkFWtTgYeBmal8hOAp4BPkH37nwB0pHm3AB/KbecbwL/0sp+XAPcArwf2BH4OfCHNmwwEsFMvyx4MrAPekfZxDrChap+uzpUP4C9y44uBc6viXAD8WdqfHwFfzr0fG4Cvpm2NBY4A/gh0pGN9VjqmO+eO773AXmmdDwMX5NbXXWu/cvFcATyX3odW4A7gMeDMtL0vklWjkf4PVgCfIfv/eifZ/8hBaf584AZgHHAo8CRwV5o3DlgFnJPe6yPSdg/OxfHFNPxlYG7a3mjg7YAG+/M4VF+DHoBfDXiTe08WP82NHwz0pOEO4PdV5T8NXF5we53AN3LL/aBGmVFAD3BYjXnbnJzYNln8V50YZlW2S5aoHuil3PuAn6XhFuBp4Oheyq4E3pMbPx54PA1Ppu9kcREwPzc+DniVASQLQMDLwAG5+W8FHssdv1eB1tz8b5MSW27aI8Bf547vB3Lz/i8wt7f3o8b+XQF8Jzf+UeDh3PhfAavT8NvTcR6Vm39dOgYtZF8E3pSb909sSRbvA+6s2va/Ap/PxVFJFpcA/5E/jn4N/OW6zJHt6dzwn4DWVL+9L1m1w+rc/BbgzlorkdQBfIXsW+AYsm+z/55m70N2kq02kewbaK15RayqiuFAsm/rR5E16O9EdnXUVwyQnUzmStoPOAh4KSLu7aXsXsATufEn0rQi9srHHBEvS3q+4LLV9iTbx2WSKtNE9h5VPBsR63Pj+wJnSfpobtoYto6/+v+h6L5VPJMb7qkxPj4N7wWsiohNuflPkF1h7kn23q2qmlexL9BR9b+5E/C9GvF8jSwB/SQdp3+LiK8U3RnbmuvvrJZVZN9Sd8+9JkTEe3opfy1Zlcg+EbEb2aW/cus6oMYyz5FVg9Wa9zLZyRAASS1kJ5G86sclfxv4DTAlInYlq+LIx7B/rcDTCfUG4APADGqfdCr+QHayqnhjmlbEU2RJCwBJu5BVyQ3Ec2Qn30Ny789ukd3MUFF9fFYBX6p6T3eJiOsKbG9HP5r6D8A+Ve0HbySrbnqWrAptn6p5FauAJVX7MT4iPrRN0BFrI+ITEbE/cDIwW9K0HbwvI4aThdVyL7A2NZCOldQi6VBJb+ml/ATghYhYL+lo4P25edcAx0n6W0k7pcbLw9O3ysuAOcoa01skvVXSzsBvya5yTkwNzZ8ju1rpywRgDbBO0puA/MnjZuANkmalhuEJ6Wqo4irgbLITSl/J4jrgc5L2lDSRrGqp6G9VbgROUtbYP4asimRAn7907L4DfEPS6wEk7S3p+D4W+w5wgaQOZcal4zuhwCafAfaQtNtA4q2hi+zK5R8ljVZ2a+57yarpNgLfBy6WtIukg8naVypuBg5MNwuMTq+3SPrL6o2kBv2/UHZZ8RLZreObqstZMU4Wto30gT0JOJyskfI5YB7Q28niw8AlktaSnUBvyK3r92SN6J8AXgAeBA5Lsy8Efgncl+Z9lawe+6W0znlk3zZfBra6O6qGC8mS1FqyE+P1uRjWAu8iOyE9DfyO7O6iyvyfkZ1E7o+IfJVHtS8CS4FfpLjvT9PqiojlwEfIrsKeAl4ssE99+SRZI/E9yu4I+ylZNVpv218KnAdcmra9gixBFon9N2SJ8tF0Z1F/q6eq1/cq2XvxP8j+t74FnJm2AzCTrMrqabI2iMtzy64F3g2cQXaF8jRbGvKrTSE7LuuAu4FvRcSi7Yl9JFOEOz8yS7enXhsR8+oWNhuBnCxsxEvVa7eRtbmsHex4zJqRq6FsRJN0JVlVxSwnCrPe+crCzMzq8pWFmZnV5WRhZmZ1DZtfcE+cODEmT5484OVffvllxo0bt+MC2kEcV3HNGBM4rv5oxphgeMe1bNmy5yKi+kev2xrs543sqFd7e3tsj0WLFm3X8mVxXMU1Y0wRjqs/mjGmiOEdF7A0CpxjXQ1lZmZ1OVmYmQ0lPT1QfRdrRDa9RE4WZmZDRU8PTJsGs2dvSRgR2fi0aaUmDCcLM7OhorUVOjqgszNLEJD97ezMpre2lrbpYXM3lJnZsCfBnDnZcGcntLVlf2fNyqZv6d9kh/OVhZnZUJJPGBUlJwpwsjAzG1oqbRR5+TaMkjhZmJkNFZVEUal6am/P/lbaMEpMGG6zMDMbKtavh66uLW0US5ZsqZLq6srmjx1byqadLMzMhoqxY+H227O7niptFJU2jBITBThZmJkNLbUSglRqooCS2ywknSDpEUkrJH2qj3KnSQpJR6XxyZJ6JD2YXnPLjNPMzPpW2pWFpBbgm8C7yDqmv0/Sgoj4dVW5CcDHga6qVayMiMPLis/MzIor88riaGBFRDwaEa8C84HpNcp9AfgqsL7EWMzMbDuU1q2qpNOBEyLi3DQ+A+iIiJm5MkcCn42I0yQtBi6MiKWSJgPLgd8Ca4DPRcSdNbZxPnA+wKRJk9rnz58/4HjXrVvH+PHjB7x8WRxXcc0YEziu/mjGmGB4xzV16tRlEXFU3YJFnmM+kBdwOjAvNz4DuDQ3PgpYDExO44uBo9LwzsAeabgdWAXs2tf23J9FYzVjXM0YU4Tj6o9mjClieMdFE/Rn8SSwT268LU2rmAAcCiyW9DhwDLBA0lER8UpEPA8QEcuAlcCBJcZqZmZ9KDNZ3AdMkbSfpDHAGcCCysyIeCkiJkbE5IiYDNwDnBxZNdSeqYEcSfsDU4BHS4zVzMz6UNrdUBGxQdJMYCHQAlwWEcslXUJ22bOgj8XfAVwi6TVgE3BBRLxQVqxmZta3Un+UFxG3ALdUTbuol7LH5oZvAm4qMzYzMyvODxI0M7O6nCzMzKwuJwszM6vLycLMBlVPz7bdMERk0615OFmY2aDp6YFp07but6fSv8+0aU4YzcTJwswGTWsrdHRs6egNtnQE19GRzbfm4P4szGzQVPrtgSxBtLVt6TF0zpwt/fvY4Ct0ZSHp+5JOlOQrETPbofIJo8KJovkUPfl/C3g/8DtJX5F0UIkxmdkIUmmjyMu3YVhzKJQsIuKnEfH3wJHA48BPJf1c0jmSRpcZoJkNX5VEUal6am/P/lbaMJwwmkfhNgtJewAfIHvU+APANcDbgLOAY8sIzsyGt/XroatrSxvFkiVbqqS6urL5JXctbQUVShaSfgAcBHwPeG9EPJVmXS9paVnBmdnwNnYs3H57dtdTpY2i0obhRNFcil5Z/HNELKo1I4r0sGRm1otaCUFyomg2RRu4D5a0e2VE0uskfbikmMzMrMkUTRbnRcTqykhEvAicV05IZmbWbIomixZpy13PqRe7MeWEZGZmzaZom8WPyRqz/zWNfzBNMzOzEaBosvgkWYL4UBq/DZhXSkRmZtZ0CiWLiNgEfDu9zMxshCn6O4spwJeBg4HNz4GMiP1LisvMzJpI0Qbuy8muKjYAU4GrgKvLCsrMzJpL0WQxNiJuBxQRT0TExcCJ5YVlZmbNpGgD9yvp8eS/kzQTeBIYX15YDdLTs/VzBiB7cpmfM2BmtpWiVxYfB3YBPga0kz1Q8Kx6C0k6QdIjklZI+lQf5U6TFJKOyk37dFruEUnHF4yzOPfnaGZWWN0ri/QDvPdFxIXAOuCcIitOy30TeBfQDdwnaUFE/Lqq3ASyZNSVm3YwcAZwCLAX2SPRD4yIjYX2qoh8f44A06dv/axk9+doZrZZ3WQRERslvW0A6z4aWBERjwJImg9MB35dVe4LwFeB/52bNh2YHxGvAI9JWpHWd/cA4qjN/TmamRVWtBrqAUkLJM2Q9DeVV51l9gZW5ca707TNJB0J7BMR/9nfZXcI9+doZlaIokBXVJIurzE5IuIf+ljmdOCEiDg3jc8AOiJiZhofBdwBnB0Rj0taDFwYEUslXQrcExFXp7LfBW6NiBurtnE+cD7ApEmT2ufPn193X7bR3Q3PPMO6tjbGd3fDpEnZVUaTWLduHePHN9+9BM0YVzPGBI6rP5oxJhjecU2dOnVZoa4mIqKUF/BWYGFu/NPAp3PjuwHPkXXT+jiwHvgDcFSNsguBt/a1vfb29uiXTZsiZs2KgIhZs2LRokVbjcemTf1bX0kWLVo02CHU1IxxNWNMEY6rP5oxpojhHRewNAqc04v+gvtyYJtLkOjjygK4D5giaT+yW23PAN6fW/YlYGJuG4vZcmXRA1wraQ5ZA/cU4N4isRbm/hzNzAor+juLm3PDrcCpZFcBvYqIDek3GQuBFuCyiFgu6RKyTLagj2WXS7qBrDF8A/CR2JF3QoH7czQz64eiDxK8KT8u6TrgrgLL3QLcUjXtol7KHls1/iXgS0XiGzD352hmVkjRu6GqTQFevyMDMTOz5lW0zWItW7dZPE3Wx4WZmY0ARauhJpQdiJmZNa9C1VCSTpW0W258d0mnlBeWmZk1k6JtFp9Pt7oCEBGrgc+XE5KZmTWbosmiVrmit92amdkQVzRZLJU0R9IB6TUHWFZmYGZm1jyKJouPAq8C1wPzyR7N8ZGygjIzs+ZS9G6ol4FeOy8yM7PhrejdULdJ2j03/jpJC8sLy8zMmknRaqiJ6Q4oACLiRfwLbjOzEaNostgk6Y2VEUmTqfEUWjMzG56K3v76WeAuSUsAAW8ndTpkZmbDX9EG7h9LOoosQTwA/BDoKTMwMzNrHkUfJHgu8HGgDXgQOAa4G3hneaGZmVmzKNpm8XHgLcATETEVOAJY3fciZmY2XBRNFusjYj2ApJ0j4jfAQeWFZWZmzaRoA3d3+p3FD4HbJL0IPFFeWGZm1kyKNnCfmgYvlrQI2A34cWlRmZlZU+n3k2MjYkkZgZiZWfMaaB/cZmY2gjhZmJlZXU4WZmZWl5OFmZnVVWqykHSCpEckrZC0TX8Yki6Q9EtJD0q6S9LBafpkST1p+oOS5pYZp5mZ9a20frQltQDfBN4FdAP3SVoQEb/OFbs2Iuam8icDc4AT0ryVEXF4WfGZmVlxZV5ZHA2siIhHI+JVsu5Yp+cLRMSa3Og4/NhzM7OmpIhyzs+STgdOiIhz0/gMoCMiZlaV+wgwGxgDvDMifpf6y1gO/BZYA3wuIu6ssY3zSY9KnzRpUvv8+fMHHO+6desYP378gJcvi+MqrhljAsfVH80YEwzvuKZOnbosIo6qWzAiSnkBpwPzcuMzgEv7KP9+4Mo0vDOwRxpuB1YBu/a1vfb29tgeixYt2q7ly+K4imvGmCIcV380Y0wRwzsuYGkUOKeXWQ31JLBPbrwtTevNfOAUgIh4JSKeT8PLgJXAgSXFaQVt3NhTSeybRQQbN7prE7PhrsxkcR8wRdJ+ksYAZwAL8gUkTcmNngj8Lk3fMzWQI2l/YArwaImxWh0bN/bw0EPTWLly9uaEERGsXDmbhx6a5oRhNsyVdjdURGyQNBNYCLQAl0XEckmXkF32LABmSjoOeA14ETgrLf4O4BJJrwGbgAsi4oWyYrX6Ro1qZdddO+ju7kxTprNy5Wy6uztpa5vFqFGtgxqfmZWrtGQBEBG3ALdUTbsoN/zxXpa7CbipzNisfyRxwAFzAOju7mTdurbNieKAA+YgaZAjNLMy+RfcVlg+YVQ4UZiNDE4WVliljSIv34ZhW/S8VvtmgJ7X3LZjQ5OThRVSSRSVqqfx49tpa5tFd3enE0aVntd6mHbVNGYv3PpmgNkLZzPtqmlOGDYkldpmYcPHpk3rWbOma3MbRXf3ks1VUmvWdLFp03paWsYOcpTNoXWnVjr27qCzK7sZYHrrdGYvnE1nVyezOmbRupNvBrChx8nCCmlpGcthh93OqFGtm9soKm0YThRbk8Sc47NE2tnVSduBbXT+NksUc453G48NTa6GssJaWsZuc6KT5ERRQz5hVDhR2FDmZGFWgkobRV6+DcNsqHE1lNkOVkkUlTaK9tZ2Zr1u1uY2DF9h2FDkZGG2g63fsJ6uJ7s2t1EsWbJkc5VU15NdrN+wnrGjXXVnQ4uThdkONnb0WG4/83Zad9r6ZoA5x89xorAhy8nCrAS1EoIkJwobstzAbWZmdZXWU16jSXoWeGI7VjEReG4HhbMjOa7imjEmcFz90YwxwfCOa9+I2LNeoWGTLLaXpKVRpGvBBnNcxTVjTOC4+qMZYwLHBa6GMjOzApwszMysLieLLf5tsAPoheMqrhljAsfVH80YEzgut1mYmVl9vrIwM7O6RlyykHSCpEckrZD0qRrzd5Z0fZrfJWlyk8R1tqRnJT2YXuc2IKbLJP1R0q96mS9J/5xi/oWkI5sgpmMlvZQ7ThfVKldCXPtIWiTp15KWS9qmf/lGH6+CMTX8eElqlXSvpIdSXP+nRpmGfw4LxtXwz2HaboukByTdXGNeY45VRIyYF9ACrAT2B8YADwEHV5X5MDA3DZ8BXN8kcZ0NXNrg4/UO4EjgV73Mfw9wKyDgGKCrCWI6Frh5EP633gAcmYYnAL+t8R429HgVjKnhxyvt//g0PBroAo6pKjMYn8MicTX8c5i2Oxu4ttZ71ahjNdKuLI4GVkTEoxHxKjAfmF5VZjpwZRq+EZim8h8RWiSuhouI/wJe6KPIdOCqyNwD7C7pDYMc06CIiKci4v40vBZ4GNi7qlhDj1fBmBou7f+6NDo6vaobTxv+OSwYV8NJagNOBOb1UqQhx2qkJYu9gVW58W62/fBsLhMRG4CXgD2aIC6A01L1xY2S9ik5piKKxt1ob01VCbdKOqTRG0/VAEeQfTPNG7Tj1UdMMAjHK1WrPAj8EbgtIno9Vg38HBaJCxr/OewE/hHY1Mv8hhyrkZYshrIfAZMj4s3AbWz5JmFbu5/s8QWHAf8C/LCRG5c0HrgJmBURaxq57d7UiWlQjldEbIyIw4E24GhJhzZiu/UUiKuhn0NJJwF/jIhlZW6niJGWLJ4E8t8E2tK0mmUk7QTsBjw/2HFFxPMR8UoanQe0lxxTEUWOZ0NFxJpKVUJE3AKMljSxEduWNJrspHxNRHy/RpGGH696MQ3m8UrbXA0sAk6omjUYn8O6cQ3C5/C/AydLepysevqdkq6uKtOQYzXSksV9wBRJ+0kaQ9YYtKCqzALgrDR8OnBHpJajwYyrqm77ZLL658G2ADgz3eVzDPBSRDw1mAFJ+vNKfa2ko8n+x0s/yaRtfhd4OCLm9FKsocerSEyDcbwk7Slp9zQ8FngX8JuqYg3/HBaJq9Gfw4j4dES0RcRksvPCHRHxgapiDTlWI6o/i4jYIGkmsJDsDqTLImK5pEuApRGxgOzD9T1JK8gaUs9okrg+JulkYEOK6+yy45J0HdndMhMldQOfJ2v0IyLmAreQ3eGzAvgTcE4TxHQ68CFJG4Ae4IwGJHvIvgHOAH6Z6rwBPgO8MRdbo49XkZgG43i9AbhSUgtZcrohIm4e7M9hwbga/jmsZTCOlX/BbWZmdY20aigzMxsAJwszM6vLycLMzOpysjAzs7qcLMzMrC4nC7MaJC2WVHrfxpI+JulhSdeUuI3J6uUpvf0pYyPbiPqdhVkjSNopPaOniA8Dx0VEd5kxmW0vX1nYkJW+DT8s6TvK+h/4Sfrl7VZXBpImpsclVPoj+KGk2yQ9LmmmpNnK+gq4R9Kf5TYxQ1mfBb9Kv25G0jhlfWrcm5aZnlvvAkl3ALfXiHV2Ws+vJM1K0+aSPZb+Vkn/q6p8oTglHZ7GfyHpB5Jel6a3K3s44EPAR3LrbZH0NUn3pWU+uGPeDRvunCxsqJsCfDMiDgFWA6cVWOZQ4G+AtwBfAv4UEUcAdwNn5srtkh4q92HgsjTts2SPUzgamAp8TdK4NO9I4PSI+Ov8xiS1k/1au4OsH4vzJB0RERcAfwCmRsQ3BhjnVcAn04Ptfkn2i3aAy4GPpgcE5v1PsseMvCWt9zxJ+/V9uMycLGzoeywiKo+yWAZMLrDMoohYGxHPkj3O+Udp+i+rlr8ONvehsWt6btC7gU+lx2csBlpJj88ge6R1rb423gb8ICJeTg/t+z7w9u2NU9JuwO4RsSRNvxJ4R4pz9xQ3wPdy63w32fOpHiR7XPkeZAnXrE9us7Ch7pXc8EZgbBrewJYvQ619LLMpN76JrT8T1c/CCbLe1E6LiEfyMyR1AC/3K/L6isbZHyK74li41cQGdR9sQ5evLGy4epwtj48+fYDreB+ApLeRVd28RPawx4/mntR6RIH13AmcImmXVGV1apq2XVI8L0qqXKXMAJakx2uvTnED/H1usYVkDw4cneI/MFeNZtYrX1nYcPV14AZJ5wP/OcB1rJf0ANlTbf8hTfsCWc9lv5A0CngMOKmvlUTE/ZKuAO5Nk+ZFxAMDjKnaWcBcSbsAj7LlSbbnAJdJCuAnufLzyKra7k8J71nglB0Uiw1jfuqsmZnV5WooMzOry8nCzMzqcrIwM7O6nCzMzKwuJwszM6vLycLMzOpysjAzs7qcLMzMrK7/DwdIJjdgiIJfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! -*-coding:utf8-*-\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "reg_lambda = 0.001\n",
    "epsilon = 0.000001\n",
    "epsilon_base = 0.000001\n",
    "num_examples = 0\n",
    "num_passes = 7000\n",
    "gamma = 0.2\n",
    "\n",
    "\n",
    "def plot_result(loss_arr, acc_arr, layer_arr, name):\n",
    "    loss_result_reshape = np.array(loss_arr).T\n",
    "\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(len(layer_arr)):\n",
    "        ax.plot(loss_result_reshape[:, i], label='number of %i model' % i)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)  # 增加格点\n",
    "    plt.axis('tight')  # 坐标轴适应数据量 axis 设置坐标轴\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('The loss of different models')\n",
    "    plt.savefig('The loss %s' % name)\n",
    "\n",
    "    ax = plt.subplot(211)\n",
    "    colors = ['r', 'y', 'g', 'b', 'r', 'y', 'g', 'b', 'orange']\n",
    "    for i in range(len(layer_arr)):\n",
    "        #     ax.plot(label='number of layer %i' %input_dim[i])\n",
    "        plt.scatter(i, acc_arr[i], c=colors[i % 4], cmap='brg', s=40, marker='x')\n",
    "        #     plt.legend('number of layer %i' %input_dim[i])\n",
    "\n",
    "    plt.grid(True)  # 增加格点\n",
    "    plt.axis('tight')  # 坐标轴适应数据量 axis 设置坐标轴\n",
    "    plt.xlabel('number of model')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('The accuracy of different models')\n",
    "    plt.savefig('The accuracy %s' % name)\n",
    "\n",
    "\n",
    "def fetch_data():\n",
    "    categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "    newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "    newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "    # pprint(newsgroups_train.data[0])\n",
    "\n",
    "    num_train = len(newsgroups_train.data)\n",
    "    num_test = len(newsgroups_test.data)\n",
    "\n",
    "    print('num train:',num_train)\n",
    "    print('num test :',num_test)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=20)\n",
    "\n",
    "    x = vectorizer.fit_transform(newsgroups_train.data + newsgroups_test.data)\n",
    "    x_train = x[0:num_train, :]\n",
    "    x_test = x[num_train:num_train + num_test, :]\n",
    "\n",
    "    y_train = newsgroups_train.target\n",
    "    y_test = newsgroups_test.target\n",
    "\n",
    "    print('X_train shape:',x_train.shape)\n",
    "    print('Y_train shape:',y_train.shape)\n",
    "\n",
    "    print('X_test shape:',x_test.shape)\n",
    "    print('Y_test shape:',y_test.shape)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def update_learn_rate(rate, method=\"fixed\", iters=0):\n",
    "    if method == \"step\":\n",
    "        rate *= np.power(gamma, (iters/num_passes))\n",
    "    elif method == \"exp\":\n",
    "        rate *= np.power(gamma, iters)\n",
    "    elif method == \"inv\":\n",
    "        pass\n",
    "        # rate *= np.power((1 + gamma * iters), (-power))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "class init_m(object):\n",
    "    def __init__(self, m_x):\n",
    "        self.a = m_x\n",
    "\n",
    "\n",
    "class end_m(object):\n",
    "    def __init__(self, e_x):\n",
    "        self.a = e_x\n",
    "\n",
    "\n",
    "class softmax(object):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.w = np.random.randn(in_dim, out_dim) / np.sqrt(in_dim)\n",
    "        self.b = np.zeros((1, out_dim))\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        self.delta = None\n",
    "        self.z = None\n",
    "        self.a = None\n",
    "\n",
    "    def forward(self, f_x):\n",
    "        self.z = f_x.dot(self.w) + self.b\n",
    "        exp_scores = np.exp(self.z)\n",
    "        self.a = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "        return self.a\n",
    "\n",
    "    def backprop(self, font_layer, back_layer):\n",
    "        self.delta = self.a\n",
    "        self.delta[range(num_examples), back_layer.a] -= 1\n",
    "        self.dw = font_layer.a.T.dot(self.delta)\n",
    "        self.db = np.sum(self.delta, axis=0, keepdims=True)\n",
    "\n",
    "        self.dw += reg_lambda * self.w\n",
    "        self.w += -epsilon * self.dw\n",
    "        self.b += -epsilon * self.db\n",
    "\n",
    "\n",
    "class relu(object):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.w = np.random.randn(in_dim, out_dim) / np.sqrt(in_dim)\n",
    "        self.b = np.zeros((1, out_dim))\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        self.delta = None\n",
    "        self.z = None\n",
    "        self.a = None\n",
    "        self.grad = None\n",
    "\n",
    "    def forward(self, f_x):\n",
    "        self.z = f_x.dot(self.w) + self.b\n",
    "        self.a = np.where(self.z < 0, 0, self.z)\n",
    "        self.grad = np.where(self.a < 0, 0, 1)\n",
    "        return self.a\n",
    "\n",
    "    def backprop(self, font_layer, back_layer):\n",
    "        self.delta = back_layer.delta.dot(back_layer.w.T) * self.grad\n",
    "        self.dw = font_layer.a.T.dot(self.delta)\n",
    "        self.db = np.sum(self.delta, axis=0, keepdims=True)\n",
    "\n",
    "        self.dw += reg_lambda * self.w\n",
    "        self.w += -epsilon * self.dw\n",
    "        self.b += -epsilon * self.db\n",
    "\n",
    "\n",
    "class l_tanh(object):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.w = np.random.randn(in_dim, out_dim) / np.sqrt(in_dim)\n",
    "        self.b = np.zeros((1, out_dim))\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        self.delta = None\n",
    "        self.z = None\n",
    "        self.a = None\n",
    "        self.grad = None\n",
    "\n",
    "    def forward(self, f_x):\n",
    "        self.z = f_x.dot(self.w) + self.b\n",
    "        self.a = np.tanh(self.z)\n",
    "        self.grad = 1 - np.power(self.a, 2)\n",
    "        return self.a\n",
    "\n",
    "    def backprop(self, font_layer, back_layer):\n",
    "        self.delta = back_layer.delta.dot(back_layer.w.T) * self.grad\n",
    "        self.dw = font_layer.a.T.dot(self.delta)\n",
    "        self.db = np.sum(self.delta, axis=0, keepdims=True)\n",
    "\n",
    "        self.dw += reg_lambda * self.w\n",
    "        self.w += -epsilon * self.dw\n",
    "        self.b += -epsilon * self.db\n",
    "\n",
    "\n",
    "class MLP(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.layers = [relu(20, 4),\n",
    "                       relu(4, 4),\n",
    "                       relu(4, 4),\n",
    "                       relu(4, 4),\n",
    "                       softmax(4, 20)]\n",
    "        self._loss = 1000\n",
    "        self.loss_result = []\n",
    "        self.accuracy = 0.0\n",
    "        self.learn_rate_method = \"fixed\"\n",
    "\n",
    "    def forward(self, f_x):\n",
    "        tmp = f_x\n",
    "        for layer in self.layers:\n",
    "            tmp = layer.forward(tmp)\n",
    "        return tmp\n",
    "\n",
    "    def loss(self, l_x, y):\n",
    "        l_x = self.forward(l_x)\n",
    "\n",
    "        # Calculating the loss\n",
    "        corect_logprobs = -np.log(l_x[range(num_examples), y])\n",
    "        data_loss = np.sum(corect_logprobs)\n",
    "        # Add regulatization term to loss (optional)\n",
    "        w_sum = 0\n",
    "        for layer in self.layers:\n",
    "            w_sum += np.sum(np.square(layer.w))\n",
    "\n",
    "        data_loss += reg_lambda / 2 * w_sum\n",
    "        self._loss = 1. / num_examples * data_loss\n",
    "\n",
    "    def train(self, t_x, y):\n",
    "\n",
    "        self.loss_result = []\n",
    "        for passes in range(0, num_passes):\n",
    "            self.loss(t_x, y)\n",
    "            if passes % 10 == 0:\n",
    "                self.loss_result.append(self._loss)\n",
    "                if passes % 1000 == 0:\n",
    "                    pass\n",
    "                    #print(\"Loss after iteration %i: %f\" % (passes, self._loss))\n",
    "\n",
    "            for i in range(len(self.layers)):\n",
    "                if i == 0:\n",
    "                    self.layers[-i - 1].backprop(self.layers[-i - 2], end_m(y))\n",
    "                elif i == len(self.layers) - 1:\n",
    "                    self.layers[-i - 1].backprop(init_m(t_x), self.layers[-i])\n",
    "                else:\n",
    "                    self.layers[-i - 1].backprop(self.layers[-i - 2], self.layers[-i])\n",
    "            update_learn_rate(epsilon, self.learn_rate_method, passes)\n",
    "\n",
    "    def predict(self, _x, _y):\n",
    "        n_correct = 0\n",
    "        n_test = _x.shape[0]\n",
    "        for n in range(n_test):\n",
    "            xp = _x[n, :]\n",
    "            yp = np.argmax(self.forward(xp), axis=1)\n",
    "            if yp == _y[n]:\n",
    "                n_correct += 1.0\n",
    "\n",
    "        self.accuracy = n_correct / n_test\n",
    "        print('Accuracy %f = %d / %d' % (self.accuracy, int(n_correct), n_test))\n",
    "\n",
    "\n",
    "def save_result():\n",
    "    pass\n",
    "\n",
    "def print_msg(num_node, epsilon, method, gamma, layer=3, num_pass=7000, active_func='tanh'):\n",
    "    print('num layer:',layer)\n",
    "    print('num iterations:',num_pass)\n",
    "\n",
    "    print('active func:',active_func)\n",
    "    print('num node:',num_node)\n",
    "\n",
    "    print('learn rate:',epsilon)\n",
    "    print('update method:',method)\n",
    "\n",
    "    print('reg para:',gamma)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X_train, Y_train, X_test, Y_test = fetch_data()\n",
    "    num_examples, input_dim = X_train.shape\n",
    "    Loss = []\n",
    "    Acc = []\n",
    "    Layer = []\n",
    "    np.random.seed(0)\n",
    "    layers = [[l_tanh(20, 4), l_tanh(4, 4), l_tanh(4, 4), softmax(4, 20)],\n",
    "              [l_tanh(20, 8), l_tanh(8, 8),  l_tanh(8, 8), softmax(8, 20)],\n",
    "               [l_tanh(20, 16), l_tanh(16, 16),  l_tanh(16, 16), softmax(16, 20)],\n",
    "               [l_tanh(20, 32), l_tanh(32, 32),  l_tanh(32, 32), softmax(32, 20)],\n",
    "               [l_tanh(20, 64), l_tanh(64, 64),  l_tanh(64, 64), softmax(64, 20)]             \n",
    "              ]\n",
    "    num_node = [4, 8, 16, 32, 64]\n",
    "\n",
    "    Model = MLP()\n",
    "\n",
    "    # 每次运行之前修改一下要保存的图片名称\n",
    "    pic_name = \"Tanh and epsilon:%i step for 3 layers \" %(epsilon_base)\n",
    "\n",
    "    index = 1\n",
    "    for la in layers:\n",
    "        print('model %d'%(index))\n",
    "        index += 1\n",
    "\n",
    "        epsilon = epsilon_base\n",
    "        Model.layers = la \n",
    "        #修改学习速率的改变方式 \"fixed\" “step”  “exp\"\n",
    "        Model.learn_rate_method = \"exp\"\n",
    "\n",
    "        Model.train(X_train, Y_train)\n",
    "        Loss.append(Model.loss_result)\n",
    "        Layer.append(len(la) - 1)\n",
    "\n",
    "        Model.predict(X_test, Y_test)\n",
    "        Acc.append(Model.accuracy)\n",
    "\n",
    "    plot_result(Loss, Acc, Layer, pic_name)\n",
    "    print_msg(num_node, epsilon_base, Model.learn_rate_method, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
