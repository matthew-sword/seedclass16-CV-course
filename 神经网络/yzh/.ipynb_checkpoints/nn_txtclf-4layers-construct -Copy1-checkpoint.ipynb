{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train: 2034\n",
      "num test : 1353\n",
      "X_train shape: (2034, 64)\n",
      "Y_train shape: (2034,)\n",
      "X_test shape: (1353, 64)\n",
      "Y_test shape: (1353,)\n",
      "model 1\n",
      "Accuracy 0.605322 = 819 / 1353\n",
      "model 2\n",
      "Accuracy 0.605322 = 819 / 1353\n",
      "model 3\n",
      "Accuracy 0.634146 = 858 / 1353\n",
      "model 4\n"
     ]
    }
   ],
   "source": [
    "#! -*-coding:utf8-*-\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "reg_lambda = 0.001\n",
    "epsilon = 0.00001\n",
    "epsilon_base = 0.00001\n",
    "num_examples = 0\n",
    "num_passes = 7000\n",
    "gamma = 0.2\n",
    "\n",
    "\n",
    "def plot_result(loss_arr, acc_arr, layer_arr, name):\n",
    "    loss_result_reshape = np.array(loss_arr).T\n",
    "\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(len(layer_arr)):\n",
    "        ax.plot(loss_result_reshape[:, i], label='number of %i model' % i)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)  # 增加格点\n",
    "    plt.axis('tight')  # 坐标轴适应数据量 axis 设置坐标轴\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('The loss of different models')\n",
    "    plt.savefig('The loss %s' % name)\n",
    "\n",
    "    ax = plt.subplot(211)\n",
    "    colors = ['r', 'y', 'g', 'b', 'r', 'y', 'g', 'b', 'orange']\n",
    "    for i in range(len(layer_arr)):\n",
    "        #     ax.plot(label='number of layer %i' %input_dim[i])\n",
    "        plt.scatter(i, acc_arr[i], c=colors[i % 4], cmap='brg', s=40, marker='x')\n",
    "        #     plt.legend('number of layer %i' %input_dim[i])\n",
    "\n",
    "    plt.grid(True)  # 增加格点\n",
    "    plt.axis('tight')  # 坐标轴适应数据量 axis 设置坐标轴\n",
    "    plt.xlabel('number of model')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('The accuracy of different models')\n",
    "    plt.savefig('The accuracy %s' % name)\n",
    "\n",
    "\n",
    "def fetch_data():\n",
    "    categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "    newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "    newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "    # pprint(newsgroups_train.data[0])\n",
    "\n",
    "    num_train = len(newsgroups_train.data)\n",
    "    num_test = len(newsgroups_test.data)\n",
    "\n",
    "    print('num train:',num_train)\n",
    "    print('num test :',num_test)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=64)\n",
    "\n",
    "    x = vectorizer.fit_transform(newsgroups_train.data + newsgroups_test.data)\n",
    "    x_train = x[0:num_train, :]\n",
    "    x_test = x[num_train:num_train + num_test, :]\n",
    "\n",
    "    y_train = newsgroups_train.target\n",
    "    y_test = newsgroups_test.target\n",
    "\n",
    "    print('X_train shape:',x_train.shape)\n",
    "    print('Y_train shape:',y_train.shape)\n",
    "\n",
    "    print('X_test shape:',x_test.shape)\n",
    "    print('Y_test shape:',y_test.shape)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def update_learn_rate(rate, method=\"fixed\", iters=0):\n",
    "    if method == \"step\":\n",
    "        rate *= np.power(gamma, (iters/num_passes))\n",
    "    elif method == \"exp\":\n",
    "        rate *= np.power(gamma, iters)\n",
    "    elif method == \"inv\":\n",
    "        pass\n",
    "        # rate *= np.power((1 + gamma * iters), (-power))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "class init_m(object):\n",
    "    def __init__(self, m_x):\n",
    "        self.a = m_x\n",
    "\n",
    "\n",
    "class end_m(object):\n",
    "    def __init__(self, e_x):\n",
    "        self.a = e_x\n",
    "\n",
    "\n",
    "class softmax(object):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.w = np.random.randn(in_dim, out_dim) / np.sqrt(in_dim)\n",
    "        self.b = np.zeros((1, out_dim))\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        self.delta = None\n",
    "        self.z = None\n",
    "        self.a = None\n",
    "\n",
    "    def forward(self, f_x):\n",
    "        self.z = f_x.dot(self.w) + self.b\n",
    "        exp_scores = np.exp(self.z)\n",
    "        self.a = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "        return self.a\n",
    "\n",
    "    def backprop(self, font_layer, back_layer):\n",
    "        self.delta = self.a\n",
    "        self.delta[range(num_examples), back_layer.a] -= 1\n",
    "        self.dw = font_layer.a.T.dot(self.delta)\n",
    "        self.db = np.sum(self.delta, axis=0, keepdims=True)\n",
    "\n",
    "        self.dw += reg_lambda * self.w\n",
    "        self.w += -epsilon * self.dw\n",
    "        self.b += -epsilon * self.db\n",
    "\n",
    "\n",
    "class relu(object):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.w = np.random.randn(in_dim, out_dim) / np.sqrt(in_dim)\n",
    "        self.b = np.zeros((1, out_dim))\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        self.delta = None\n",
    "        self.z = None\n",
    "        self.a = None\n",
    "        self.grad = None\n",
    "\n",
    "    def forward(self, f_x):\n",
    "        self.z = f_x.dot(self.w) + self.b\n",
    "        self.a = np.where(self.z < 0, 0, self.z)\n",
    "        self.grad = np.where(self.a < 0, 0, 1)\n",
    "        return self.a\n",
    "\n",
    "    def backprop(self, font_layer, back_layer):\n",
    "        self.delta = back_layer.delta.dot(back_layer.w.T) * self.grad\n",
    "        self.dw = font_layer.a.T.dot(self.delta)\n",
    "        self.db = np.sum(self.delta, axis=0, keepdims=True)\n",
    "\n",
    "        self.dw += reg_lambda * self.w\n",
    "        self.w += -epsilon * self.dw\n",
    "        self.b += -epsilon * self.db\n",
    "\n",
    "\n",
    "class l_tanh(object):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.w = np.random.randn(in_dim, out_dim) / np.sqrt(in_dim)\n",
    "        self.b = np.zeros((1, out_dim))\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        self.delta = None\n",
    "        self.z = None\n",
    "        self.a = None\n",
    "        self.grad = None\n",
    "\n",
    "    def forward(self, f_x):\n",
    "        self.z = f_x.dot(self.w) + self.b\n",
    "        self.a = np.tanh(self.z)\n",
    "        self.grad = 1 - np.power(self.a, 2)\n",
    "        return self.a\n",
    "\n",
    "    def backprop(self, font_layer, back_layer):\n",
    "        self.delta = back_layer.delta.dot(back_layer.w.T) * self.grad\n",
    "        self.dw = font_layer.a.T.dot(self.delta)\n",
    "        self.db = np.sum(self.delta, axis=0, keepdims=True)\n",
    "\n",
    "        self.dw += reg_lambda * self.w\n",
    "        self.w += -epsilon * self.dw\n",
    "        self.b += -epsilon * self.db\n",
    "\n",
    "\n",
    "class MLP(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.layers = [relu(20, 4),\n",
    "                       relu(4, 4),\n",
    "                       relu(4, 4),\n",
    "                       relu(4, 4),\n",
    "                       softmax(4, 20)]\n",
    "        self._loss = 1000\n",
    "        self.loss_result = []\n",
    "        self.accuracy = 0.0\n",
    "        self.learn_rate_method = \"fixed\"\n",
    "\n",
    "    def forward(self, f_x):\n",
    "        tmp = f_x\n",
    "        for layer in self.layers:\n",
    "            tmp = layer.forward(tmp)\n",
    "        return tmp\n",
    "\n",
    "    def loss(self, l_x, y):\n",
    "        l_x = self.forward(l_x)\n",
    "\n",
    "        # Calculating the loss\n",
    "        corect_logprobs = -np.log(l_x[range(num_examples), y])\n",
    "        data_loss = np.sum(corect_logprobs)\n",
    "        # Add regulatization term to loss (optional)\n",
    "        w_sum = 0\n",
    "        for layer in self.layers:\n",
    "            w_sum += np.sum(np.square(layer.w))\n",
    "\n",
    "        data_loss += reg_lambda / 2 * w_sum\n",
    "        self._loss = 1. / num_examples * data_loss\n",
    "\n",
    "    def train(self, t_x, y):\n",
    "\n",
    "        self.loss_result = []\n",
    "        for passes in range(0, num_passes):\n",
    "            self.loss(t_x, y)\n",
    "            if passes % 10 == 0:\n",
    "                self.loss_result.append(self._loss)\n",
    "                if passes % 1000 == 0:\n",
    "                    pass\n",
    "                    #print(\"Loss after iteration %i: %f\" % (passes, self._loss))\n",
    "\n",
    "            for i in range(len(self.layers)):\n",
    "                if i == 0:\n",
    "                    self.layers[-i - 1].backprop(self.layers[-i - 2], end_m(y))\n",
    "                elif i == len(self.layers) - 1:\n",
    "                    self.layers[-i - 1].backprop(init_m(t_x), self.layers[-i])\n",
    "                else:\n",
    "                    self.layers[-i - 1].backprop(self.layers[-i - 2], self.layers[-i])\n",
    "            update_learn_rate(epsilon, self.learn_rate_method, passes)\n",
    "\n",
    "    def predict(self, _x, _y):\n",
    "        n_correct = 0\n",
    "        n_test = _x.shape[0]\n",
    "        for n in range(n_test):\n",
    "            xp = _x[n, :]\n",
    "            yp = np.argmax(self.forward(xp), axis=1)\n",
    "            if yp == _y[n]:\n",
    "                n_correct += 1.0\n",
    "\n",
    "        self.accuracy = n_correct / n_test\n",
    "        print('Accuracy %f = %d / %d' % (self.accuracy, int(n_correct), n_test))\n",
    "\n",
    "\n",
    "def save_result():\n",
    "    pass\n",
    "\n",
    "def print_msg(num_node, epsilon, method, gamma, layer=3, num_pass=7000, active_func='tanh'):\n",
    "    print('num layer:',layer)\n",
    "    print('num iterations:',num_pass)\n",
    "\n",
    "    print('active func:',active_func)\n",
    "    print('num node:',num_node)\n",
    "\n",
    "    print('learn rate:',epsilon)\n",
    "    print('update method:',method)\n",
    "\n",
    "    print('reg para:',gamma)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X_train, Y_train, X_test, Y_test = fetch_data()\n",
    "    num_examples, input_dim = X_train.shape\n",
    "    Loss = []\n",
    "    Acc = []\n",
    "    Layer = []\n",
    "    np.random.seed(0)\n",
    "    layers = [[l_tanh(64, 4), l_tanh(4, 4), l_tanh(4, 4), l_tanh(4, 4), softmax(4, 4)],\n",
    "              [l_tanh(64, 8), l_tanh(8, 8), l_tanh(8, 8), l_tanh(8, 8), softmax(8, 4)],\n",
    "              [l_tanh(64, 16), l_tanh(16, 16), l_tanh(16, 16), l_tanh(16, 16), softmax(16, 4)],\n",
    "              [l_tanh(64, 32), l_tanh(32, 32), l_tanh(32, 32), l_tanh(32, 32), softmax(32, 4)],\n",
    "              [l_tanh(64, 64), l_tanh(64, 64), l_tanh(64, 64), l_tanh(64, 64), softmax(64, 4)]\n",
    "#               [l_tanh(64, 128), l_tanh(128, 128), l_tanh(128, 128), l_tanh(128, 128), softmax(128, 4)]\n",
    "#               [l_tanh(32, 256), l_tanh(256, 256), l_tanh(256, 256), l_tanh(256, 256), softmax(256, 4)]\n",
    "              ]\n",
    "    Model = MLP()\n",
    "\n",
    "\n",
    "    # 每次运行之前修改一下要保存的图片名称\n",
    "    pic_name = \"New feayure Tanh and epsilon:%i step for 3 layers \" %(epsilon_base)\n",
    "    num_node = [4, 8, 16, 32, 64]\n",
    "\n",
    "    index = 1\n",
    "    for la in layers:\n",
    "        print('model %d'%(index))\n",
    "        index += 1\n",
    "\n",
    "        epsilon = epsilon_base\n",
    "        Model.layers = la \n",
    "        #修改学习速率的改变方式 \"fixed\" “step”  “exp\"\n",
    "        Model.learn_rate_method = \"step\"\n",
    "\n",
    "        Model.train(X_train, Y_train)\n",
    "        Loss.append(Model.loss_result)\n",
    "        Layer.append(len(la) - 1)\n",
    "\n",
    "        Model.predict(X_test, Y_test)\n",
    "        Acc.append(Model.accuracy)\n",
    "\n",
    "    plot_result(Loss, Acc, Layer, pic_name)\n",
    "    print_msg(num_node, epsilon_base, Model.learn_rate_method, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
