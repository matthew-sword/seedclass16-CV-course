{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train: 2034\n",
      "num test : 1353\n",
      "X_train shape: (2034, 128)\n",
      "Y_train shape: (2034,)\n",
      "X_test shape: (1353, 128)\n",
      "Y_test shape: (1353,)\n",
      "model 1\n",
      "Accuracy 0.332594 = 450 / 1353\n",
      "model 2\n",
      "Accuracy 0.569106 = 770 / 1353\n",
      "model 3\n"
     ]
    }
   ],
   "source": [
    "#! -*-coding:utf8-*-\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "reg_lambda = 0.001\n",
    "epsilon = 0.000001\n",
    "epsilon_base = 0.000001\n",
    "num_examples = 0\n",
    "num_passes = 7000\n",
    "gamma = 0.2\n",
    "\n",
    "\n",
    "def plot_result(loss_arr, acc_arr, layer_arr, name):\n",
    "    loss_result_reshape = np.array(loss_arr).T\n",
    "\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(len(layer_arr)):\n",
    "        ax.plot(loss_result_reshape[:, i], label='number of %i model' % i)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)  # 增加格点\n",
    "    plt.axis('tight')  # 坐标轴适应数据量 axis 设置坐标轴\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('The loss of different models')\n",
    "    plt.savefig('The loss %s' % name)\n",
    "\n",
    "    ax = plt.subplot(211)\n",
    "    colors = ['r', 'y', 'g', 'b', 'r', 'y', 'g', 'b', 'orange']\n",
    "    for i in range(len(layer_arr)):\n",
    "        #     ax.plot(label='number of layer %i' %input_dim[i])\n",
    "        plt.scatter(i, acc_arr[i], c=colors[i % 4], cmap='brg', s=40, marker='x')\n",
    "        #     plt.legend('number of layer %i' %input_dim[i])\n",
    "\n",
    "    plt.grid(True)  # 增加格点\n",
    "    plt.axis('tight')  # 坐标轴适应数据量 axis 设置坐标轴\n",
    "    plt.xlabel('number of model')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('The accuracy of different models')\n",
    "    plt.savefig('The accuracy %s' % name)\n",
    "\n",
    "\n",
    "def fetch_data():\n",
    "    categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "    newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "    newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "    # pprint(newsgroups_train.data[0])\n",
    "\n",
    "    num_train = len(newsgroups_train.data)\n",
    "    num_test = len(newsgroups_test.data)\n",
    "\n",
    "    print('num train:',num_train)\n",
    "    print('num test :',num_test)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=128)\n",
    "\n",
    "    x = vectorizer.fit_transform(newsgroups_train.data + newsgroups_test.data)\n",
    "    x_train = x[0:num_train, :]\n",
    "    x_test = x[num_train:num_train + num_test, :]\n",
    "\n",
    "    y_train = newsgroups_train.target\n",
    "    y_test = newsgroups_test.target\n",
    "\n",
    "    print('X_train shape:',x_train.shape)\n",
    "    print('Y_train shape:',y_train.shape)\n",
    "\n",
    "    print('X_test shape:',x_test.shape)\n",
    "    print('Y_test shape:',y_test.shape)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def update_learn_rate(rate, method=\"fixed\", iters=0):\n",
    "    if method == \"step\":\n",
    "        rate *= np.power(gamma, (iters/num_passes))\n",
    "    elif method == \"exp\":\n",
    "        rate *= np.power(gamma, iters)\n",
    "    elif method == \"inv\":\n",
    "        pass\n",
    "        # rate *= np.power((1 + gamma * iters), (-power))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "class init_m(object):\n",
    "    def __init__(self, m_x):\n",
    "        self.a = m_x\n",
    "\n",
    "\n",
    "class end_m(object):\n",
    "    def __init__(self, e_x):\n",
    "        self.a = e_x\n",
    "\n",
    "\n",
    "class softmax(object):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.w = np.random.randn(in_dim, out_dim) / np.sqrt(in_dim)\n",
    "        self.b = np.zeros((1, out_dim))\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        self.delta = None\n",
    "        self.z = None\n",
    "        self.a = None\n",
    "\n",
    "    def forward(self, f_x):\n",
    "        self.z = f_x.dot(self.w) + self.b\n",
    "        exp_scores = np.exp(self.z)\n",
    "        self.a = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "        return self.a\n",
    "\n",
    "    def backprop(self, font_layer, back_layer):\n",
    "        self.delta = self.a\n",
    "        self.delta[range(num_examples), back_layer.a] -= 1\n",
    "        self.dw = font_layer.a.T.dot(self.delta)\n",
    "        self.db = np.sum(self.delta, axis=0, keepdims=True)\n",
    "\n",
    "        self.dw += reg_lambda * self.w\n",
    "        self.w += -epsilon * self.dw\n",
    "        self.b += -epsilon * self.db\n",
    "\n",
    "\n",
    "class relu(object):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.w = np.random.randn(in_dim, out_dim) / np.sqrt(in_dim)\n",
    "        self.b = np.zeros((1, out_dim))\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        self.delta = None\n",
    "        self.z = None\n",
    "        self.a = None\n",
    "        self.grad = None\n",
    "\n",
    "    def forward(self, f_x):\n",
    "        self.z = f_x.dot(self.w) + self.b\n",
    "        self.a = np.where(self.z < 0, 0, self.z)\n",
    "        self.grad = np.where(self.a < 0, 0, 1)\n",
    "        return self.a\n",
    "\n",
    "    def backprop(self, font_layer, back_layer):\n",
    "        self.delta = back_layer.delta.dot(back_layer.w.T) * self.grad\n",
    "        self.dw = font_layer.a.T.dot(self.delta)\n",
    "        self.db = np.sum(self.delta, axis=0, keepdims=True)\n",
    "\n",
    "        self.dw += reg_lambda * self.w\n",
    "        self.w += -epsilon * self.dw\n",
    "        self.b += -epsilon * self.db\n",
    "\n",
    "\n",
    "class l_tanh(object):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.w = np.random.randn(in_dim, out_dim) / np.sqrt(in_dim)\n",
    "        self.b = np.zeros((1, out_dim))\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        self.delta = None\n",
    "        self.z = None\n",
    "        self.a = None\n",
    "        self.grad = None\n",
    "\n",
    "    def forward(self, f_x):\n",
    "        self.z = f_x.dot(self.w) + self.b\n",
    "        self.a = np.tanh(self.z)\n",
    "        self.grad = 1 - np.power(self.a, 2)\n",
    "        return self.a\n",
    "\n",
    "    def backprop(self, font_layer, back_layer):\n",
    "        self.delta = back_layer.delta.dot(back_layer.w.T) * self.grad\n",
    "        self.dw = font_layer.a.T.dot(self.delta)\n",
    "        self.db = np.sum(self.delta, axis=0, keepdims=True)\n",
    "\n",
    "        self.dw += reg_lambda * self.w\n",
    "        self.w += -epsilon * self.dw\n",
    "        self.b += -epsilon * self.db\n",
    "\n",
    "\n",
    "class MLP(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.layers = [relu(20, 4),\n",
    "                       relu(4, 4),\n",
    "                       relu(4, 4),\n",
    "                       relu(4, 4),\n",
    "                       softmax(4, 20)]\n",
    "        self._loss = 1000\n",
    "        self.loss_result = []\n",
    "        self.accuracy = 0.0\n",
    "        self.learn_rate_method = \"fixed\"\n",
    "\n",
    "    def forward(self, f_x):\n",
    "        tmp = f_x\n",
    "        for layer in self.layers:\n",
    "            tmp = layer.forward(tmp)\n",
    "        return tmp\n",
    "\n",
    "    def loss(self, l_x, y):\n",
    "        l_x = self.forward(l_x)\n",
    "\n",
    "        # Calculating the loss\n",
    "        corect_logprobs = -np.log(l_x[range(num_examples), y])\n",
    "        data_loss = np.sum(corect_logprobs)\n",
    "        # Add regulatization term to loss (optional)\n",
    "        w_sum = 0\n",
    "        for layer in self.layers:\n",
    "            w_sum += np.sum(np.square(layer.w))\n",
    "\n",
    "        data_loss += reg_lambda / 2 * w_sum\n",
    "        self._loss = 1. / num_examples * data_loss\n",
    "\n",
    "    def train(self, t_x, y):\n",
    "\n",
    "        self.loss_result = []\n",
    "        for passes in range(0, num_passes):\n",
    "            self.loss(t_x, y)\n",
    "            if passes % 10 == 0:\n",
    "                self.loss_result.append(self._loss)\n",
    "                if passes % 1000 == 0:\n",
    "                    pass\n",
    "                    #print(\"Loss after iteration %i: %f\" % (passes, self._loss))\n",
    "\n",
    "            for i in range(len(self.layers)):\n",
    "                if i == 0:\n",
    "                    self.layers[-i - 1].backprop(self.layers[-i - 2], end_m(y))\n",
    "                elif i == len(self.layers) - 1:\n",
    "                    self.layers[-i - 1].backprop(init_m(t_x), self.layers[-i])\n",
    "                else:\n",
    "                    self.layers[-i - 1].backprop(self.layers[-i - 2], self.layers[-i])\n",
    "            update_learn_rate(epsilon, self.learn_rate_method, passes)\n",
    "\n",
    "    def predict(self, _x, _y):\n",
    "        n_correct = 0\n",
    "        n_test = _x.shape[0]\n",
    "        for n in range(n_test):\n",
    "            xp = _x[n, :]\n",
    "            yp = np.argmax(self.forward(xp), axis=1)\n",
    "            if yp == _y[n]:\n",
    "                n_correct += 1.0\n",
    "\n",
    "        self.accuracy = n_correct / n_test\n",
    "        print('Accuracy %f = %d / %d' % (self.accuracy, int(n_correct), n_test))\n",
    "\n",
    "\n",
    "def save_result():\n",
    "    pass\n",
    "\n",
    "def print_msg(num_node, epsilon, method, gamma, layer=3, num_pass=7000, active_func='tanh'):\n",
    "    print('num layer:',layer)\n",
    "    print('num iterations:',num_pass)\n",
    "\n",
    "    print('active func:',active_func)\n",
    "    print('num node:',num_node)\n",
    "\n",
    "    print('learn rate:',epsilon)\n",
    "    print('update method:',method)\n",
    "\n",
    "    print('reg para:',gamma)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X_train, Y_train, X_test, Y_test = fetch_data()\n",
    "    num_examples, input_dim = X_train.shape\n",
    "    Loss = []\n",
    "    Acc = []\n",
    "    Layer = []\n",
    "    np.random.seed(0)\n",
    "    layers = [[l_tanh(128, 4), l_tanh(4, 4), l_tanh(4, 4), l_tanh(4, 4), softmax(4, 4)],\n",
    "              [l_tanh(128, 8), l_tanh(8, 8), l_tanh(8, 8), l_tanh(8, 8), softmax(8, 4)],\n",
    "              [l_tanh(128, 16), l_tanh(16, 16), l_tanh(16, 16), l_tanh(16, 16), softmax(16, 4)],\n",
    "              [l_tanh(128, 32), l_tanh(32, 32), l_tanh(32, 32), l_tanh(32, 32), softmax(32, 4)],\n",
    "              [l_tanh(128, 64), l_tanh(64, 64), l_tanh(64, 64), l_tanh(64, 64), softmax(64, 4)]\n",
    "#               [l_tanh(64, 128), l_tanh(128, 128), l_tanh(128, 128), l_tanh(128, 128), softmax(128, 4)]\n",
    "#               [l_tanh(32, 256), l_tanh(256, 256), l_tanh(256, 256), l_tanh(256, 256), softmax(256, 4)]\n",
    "              ]\n",
    "    Model = MLP()\n",
    "\n",
    "\n",
    "    # 每次运行之前修改一下要保存的图片名称\n",
    "    pic_name = \"New feature 128 Tanh and epsilon:%i step for 3 layers \" %(epsilon_base)\n",
    "    num_node = [4, 8, 16, 32, 64]\n",
    "\n",
    "    index = 1\n",
    "    for la in layers:\n",
    "        print('model %d'%(index))\n",
    "        index += 1\n",
    "\n",
    "        epsilon = epsilon_base\n",
    "        Model.layers = la \n",
    "        #修改学习速率的改变方式 \"fixed\" “step”  “exp\"\n",
    "        Model.learn_rate_method = \"step\"\n",
    "\n",
    "        Model.train(X_train, Y_train)\n",
    "        Loss.append(Model.loss_result)\n",
    "        Layer.append(len(la) - 1)\n",
    "\n",
    "        Model.predict(X_test, Y_test)\n",
    "        Acc.append(Model.accuracy)\n",
    "\n",
    "    plot_result(Loss, Acc, Layer, pic_name)\n",
    "    print_msg(num_node, epsilon_base, Model.learn_rate_method, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    plot_result(Loss, Acc, Layer, pic_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
